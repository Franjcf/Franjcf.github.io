---
layout: default
modal-id: 6
date: 2014-07-15
img: gradient_decent.png
alt: image-alt
project-date: April 2014
client: Start Bootstrap
category: Web Development
description: 
Summary: 'In this mini-project I code gradient decent from scratch to solve linear regression and ridge regularization problems. These particular problems were chosen because their analytical solutions are well-known. Furthermore I investigate how the gradient step size affects the rate of convergence of the underlying optimization problem. I then proceed by calculating the largest and smallest eigenvalues of the second derivative of objective function in order to set optimal step size and to find the lower bound the rate of convergence. Finally I investigate how the regularization term (lambda) affects said convergence rate.'
---
